# âœ… Week 4: Baseline Modeling & Evaluation

---

## ğŸ¯ Objective

To train and evaluate baseline machine learning models (**Logistic Regression**, **Decision Tree**, **Random Forest**) using the **original imbalanced dataset**.  
Focus is on **Recall**, **Precision**, **F1-score**, and **ROC-AUC**, rather than accuracy, which can be **misleading** in highly imbalanced datasets.

---

## ğŸ“Š Model-wise Performance Insights

### ğŸ”¹ 1. Logistic Regression (`class_weight='balanced'`)

- **Recall (Fraud)**: âœ… 91.84% â€” Excellent fraud detection  
- **Precision (Fraud)**: âŒ 6.09% â€” Very poor, high false positives  
- **F1-score (Fraud)**: âŒ 0.1141 â€” Low due to imbalance in precision/recall  
- **ROC-AUC**: âœ… 0.9722 â€” Excellent separation between classes  
- **Accuracy**: 97.55% â€” High, but **misleading**

ğŸ“Œ **Verdict**:  
Prioritizes catching **all frauds**, but at the cost of flagging **too many legitimate transactions** as fraud.  
Not viable alone without **filtering or review pipeline**.

---

### ğŸ”¹ 2. Decision Tree (`class_weight='balanced'`)

- **Recall (Fraud)**: âš ï¸ 71.43% â€” Catches most but not all frauds  
- **Precision (Fraud)**: âœ… 70.71% â€” Good balance  
- **F1-score (Fraud)**: âœ… 0.7107 â€” Strong trade-off  
- **ROC-AUC**: âš ï¸ 0.8569 â€” Moderate separation ability  
- **Accuracy**: 99.90% â€” Still **misleading**

ğŸ“Œ **Verdict**:  
Better **fraud/no-fraud balance**, but less powerful than logistic or random forest in **overall discrimination**.

---

### ğŸ”¹ 3. Random Forest (`class_weight='balanced'`)

- **Recall (Fraud)**: âœ… 75.51%  
- **Precision (Fraud)**: âœ… 96.10% â€” Very few false alarms  
- **F1-score (Fraud)**: âœ… 0.8457 â€” Best so far  
- **ROC-AUC**: âœ… 0.9581  
- **Accuracy**: âœ… 99.95% â€” High but not relied upon

ğŸ“Œ **Verdict**:  
**Best baseline performer overall** â€” excellent **precision**, strong **F1-score**, and decent **recall**.  
A good candidate for **real-world deployment** or as a foundation for **future tuning**.

---

## ğŸ§  Important Insight: Accuracy is Misleading

Due to **class imbalance** (only ~0.17% frauds), **accuracy isn't meaningful**.  
A model can achieve 99%+ accuracy by predicting all transactions as **non-fraud**.

ğŸ‘‰ Instead, we focus on:

- **Recall** â†’ Catching as many frauds as possible  
- **Precision** â†’ Avoiding false alarms  
- **F1-score** â†’ Balancing precision and recall  
- **ROC-AUC** â†’ Measuring discrimination ability

---

## ğŸ“ Assets Produced

- âœ… Trained models: Logistic Regression, Decision Tree, Random Forest  
- âœ… Evaluation metrics & ROC curve visualizations  
- âœ… Comparison of model performance by class

---

## ğŸ“Œ Takeaway

- ğŸŒ² **Random Forest** is the **best performer** in Week 4.
- ğŸ“‰ **Logistic Regression** offers **maximum recall**, but is not usable alone due to **high false positives**.
- ğŸŒ³ **Decision Tree** provides a **balanced baseline**.

---

## ğŸ”„ Next Steps

Use **SMOTE** or other **resampling techniques** to improve the **recallâ€“precision tradeoff** further in Week 5.

